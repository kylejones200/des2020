<!DOCTYPE html><html lang="en-us" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Kyle Jones">

  
  
  
    
  
  <meta name="description" content="ANOVA Basics In the last couple of chapters, we have discussed how to make inferences about the differences in two populations in terms of means and proportions. What if we wanted to compare more than two populations simultaneously?">

  
  <link rel="alternate" hreflang="en-us" href="/courses/bana3363/11-anova-basics/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="/courses/bana3363/11-anova-basics/">

  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Kyle Jones">
  <meta property="og:url" content="/courses/bana3363/11-anova-basics/">
  <meta property="og:title" content="ANOVA Basics | Kyle Jones">
  <meta property="og:description" content="ANOVA Basics In the last couple of chapters, we have discussed how to make inferences about the differences in two populations in terms of means and proportions. What if we wanted to compare more than two populations simultaneously?"><meta property="og:image" content="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png">
  <meta property="twitter:image" content="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2020-07-28T15:19:27&#43;00:00">
    
    <meta property="article:modified_time" content="2020-07-28T15:19:27&#43;00:00">
  

  



  


  


  





  <title>ANOVA Basics | Kyle Jones</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Kyle Jones</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Kyle Jones</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/courses"><span>Courses</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link js-theme-selector" data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-palette" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      

    </ul>

  </div>
</nav>


  

<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      





  
    
  




<form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-3" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <span><i class="fas fa-bars"></i></span>
  </button>

  
  <input name="q" type="search" class="form-control" placeholder="Search..." autocomplete="off">
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  

  
  
  
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/courses/bana3363/">Overview</a>

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/courses/bana3363/1-basic-statistics-concepts/">Descriptive Statistics</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/courses/bana3363/1-basic-statistics-concepts/">Basic Statistics Concepts</a>
      </li>
      
      <li >
        <a href="/courses/bana3363/2-the-normal-distribution/">The Normal Distribution</a>
      </li>
      
      <li >
        <a href="/courses/bana3363/2-types-of-statistical-analysis/">Types of Statistical Analysis</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/courses/bana3363/6-hypothesis-testing-for-a-proportion/">Hypothesis Testing and Inference</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/courses/bana3363/6-hypothesis-testing-for-a-proportion/">Hypothesis Testing for a Proportion</a>
      </li>
      
      <li >
        <a href="/courses/bana3363/7-interval-for-differences-in-means-independent-samples/">Interval for Differences in Means--Independent Samples</a>
      </li>
      
      <li >
        <a href="/courses/bana3363/11-test-for-differences-in-proportions-independent-samples/">Hypothesis Test for a Difference in Proportion (Independent Samples)</a>
      </li>
      
      <li >
        <a href="/courses/bana3363/8-intervals-for-differences-in-proportions-independent-samples/">Intervals for Differences in Proportions--Independent Samples</a>
      </li>
      
      <li >
        <a href="/courses/bana3363/5-ci-for-mean/">Confidence Interval for the Mean</a>
      </li>
      
      <li >
        <a href="/courses/bana3363/5-1-hypothesis-testing-basics/">Hypothesis Testing for a Population Mean</a>
      </li>
      
      <li >
        <a href="/courses/bana3363/9-confidence-interval-for-matched-pairs/">Confidence Interval for Matched Pairs</a>
      </li>
      
      <li >
        <a href="/courses/bana3363/9-1-test-for-diff-in-means-proportions/">Test for Diff in Means, Proportions</a>
      </li>
      
      <li >
        <a href="/courses/bana3363/10-1-test-for-differences-in-proportions-independent-samples/">Test for Differences in Proportions--Independent Samples</a>
      </li>
      
      <li >
        <a href="/courses/bana3363/10-2-test-for-diff-in-means-independent-samples/">Test for Diff in Means Independent Samples</a>
      </li>
      
      <li class="active">
        <a href="/courses/bana3363/11-anova-basics/">ANOVA Basics</a>
      </li>
      
      <li >
        <a href="/courses/bana3363/12-anova-mc/">ANOVA - Bonferroni Method of Multiple Comparisons</a>
      </li>
      
      <li >
        <a href="/courses/bana3363/13-chi-squared-goodness-of-fit-test/">Chi Squared Tests</a>
      </li>
      
      <li >
        <a href="/courses/bana3363/8-matched-pairs/">Matched Pairs</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/courses/bana3363/15-intro-to-regression/">Regression</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/courses/bana3363/15-intro-to-regression/">Intro to Regression</a>
      </li>
      
      <li >
        <a href="/courses/bana3363/18-multiple-linear-regression/">Multiple Linear Regression</a>
      </li>
      
    </ul>
    

  </div>
  
  
</nav>

    </div>

    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>

      <nav id="TableOfContents">
  <ul>
    <li><a href="#anova-basics">ANOVA Basics</a></li>
  </ul>
</nav>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article">

        <div class="docs-article-container">
          <h1>ANOVA Basics</h1>

          <div class="article-style">
            <h2 id="anova-basics">ANOVA Basics</h2>
<p>In the last couple of chapters, we have discussed how to make inferences about the differences in two populations in terms of means and proportions. What if we wanted to compare more than two populations simultaneously? For example, what if we wanted to compare the abilities of four different real estate appraisal firms in terms of how accurate they are in predicting the sale price of a home? For convenience, we could label the firms with numbers (Firm $1$, Firm $2$, Firm $3$, Firm $4$). To compare the firms&rsquo; accuracy, you might randomly assign each firm $10$ houses to appraise and then calculate an accuracy measure, for example,</p>
<p>$$Y_{ij}=\frac{|\text{Appraised Price for home }j\text{ for Firm }i\text{ }-% \text{ Sale Price for home }j\text{ for Firm }i|}{\text{Sale Price for home }% j\text{ for Firm }i}\times 100$$</p>
<p>The question would then be whether the mean accuracy differs among the four firms. Notice that double subscripts are now required to completely identify a single observation. We must specify the group number $(i=1,2,3,4)$ and the observation number within the group $(j=1,2,\ldots ,10)$. For example, $% y_{34}=2.3$ would be the fourth observation for Firm $3$. The observed data, in general, would appear as in Table 
<a href="#anova_general">[anova_general]</a>{reference-type=&quot;ref&rdquo; reference=&quot;anova_general&rdquo;} below.</p>
<table>
<thead>
<tr>
<th><strong>Firm 1</strong></th>
<th><strong>Firm 2</strong></th>
<th><strong>Firm 3</strong></th>
<th><strong>Firm 4</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>$y_{11}$</td>
<td>$y_{21}$</td>
<td>$y_{31}$</td>
<td>$y_{41}$</td>
</tr>
<tr>
<td>$y_{12}$</td>
<td>$y_{22}$</td>
<td>$y_{32}$</td>
<td>$y_{42}$</td>
</tr>
<tr>
<td>$\vdots$</td>
<td>$\vdots$</td>
<td>$\vdots$</td>
<td>$\vdots$</td>
</tr>
<tr>
<td>$y_{1,10}$</td>
<td>$y_{2,10}$</td>
<td>$y_{3,10}$</td>
<td>$y_{4,10}$</td>
</tr>
</tbody>
</table>
<p>General appearance of an ANOVA data table for the real estate   appraisal example.</p>
<p>[[anova_general]]{#anova_general label=&quot;anova_general&rdquo;}</p>
<p>One way to do the comparisons would be to evaluate each pair of group means using the two-sample $t$ test or confidence interval that we have already studied. Thus, you would compare Firm 1 to Firm 2, Firm 1 to Firm 3, Firm 1 to Firm 4, Firm 2 to Firm 3, Firm 2 to Firm 4, and finally Firm 3 to Firm 4. The total number of comparisons would be $\binom{4}{2}=\frac{4!}{(4-2)!2!}=6$, using the combination formula from the binomial distribution (see Handout 1). In general, the number of pairs of means you would have to test if you were dealing with $g$ groups would be $\binom{g}{2}=\frac{g(g-1)}{2}$.</p>
<p>The problem is that simply conducting multiple two-sample $t$ tests is highly error prone if you look at the collection of tests as a whole. If you think about it, it makes some sense: each test has probability $\alpha$ of giving a Type I error, and if you have a collection of tests, each with a probability of error, the chance of making at least one error increases dramatically. Since making errors is generally not what we want to do when we attempt statistical inference, we need another approach. Enter ANOVA.</p>
<p><strong>ANOVA(ANalysis Of Variance)</strong> is a broad category of statistical techniques used to determine if there is a difference between two or more population/process means</p>
<p>In its simplest form, it is an extension of the two-sample $t$ test to more than two samples. You could certainly use ANOVA for the case of two samples, but it would be an unnecessary complication. Before we move on, we need to get some vocabulary out of the way.</p>
<p>A <strong>factor</strong> is a qualitative criterion by which we may segment the population. The populations can be segmented by several criteria.</p>
<p>In the appraiser example, there is only one factor, firm.  We could add another factor such as &ldquo;firm experience.&rdquo;</p>
<p>Each factor has several <strong>levels</strong> (or <strong>treatments</strong>), which are possible values of the factor. We assume each combination of factor levels defines a population or process.</p>
<p>There are four levels in the appraiser example $($Firm $1$,Firm $2$,Firm $3$, and Firm $4)$. If we add &ldquo;firm experience,&rdquo; the levels of that factor could be &ldquo;little,&rdquo; &ldquo;moderate,&rdquo; and &ldquo;significant.&rdquo;</p>
<p>The <strong>response variable</strong> is the numeric variable that we examine within each factor level combination.</p>
<p>In the appraiser example, the response variable is the appraisal accuracy.</p>
<p>The <strong>experimental unit</strong> is the entity that each value of the response variable represents.</p>
<p>In the appraiser example, the experimental unit is an individual house.</p>
<p>The design that examines only one factor with $g$ $(&gt;2)$ levels is known as the <strong>one-way ANOVA.</strong></p>
<p>We also need to get a bit of notation out of the way. Fortunately, it is a natural extension of the two-sample case to the case of $g$ populations. See Figure 
<a href="#anova_notation">[anova_notation]</a>{reference-type=&quot;ref&rdquo; reference=&quot;anova_notation&rdquo;}.</p>
<p>An additional important assumption that we will make is that the variance is the same for each of the $g$ groups, equal to $% \sigma ^{2}$. That is</p>
<p>$$\sigma_{1}^{2}=\sigma_{2}^{2}=\ldots =\sigma_{g}^{2}=\sigma ^{2}$$</p>
<p>In the one-way ANOVA, we divide the total variability in the data into two parts: that which is explained by the differences between group means and the overall mean, and that which is not. If a lot of the variability is explained by the difference between the group means and the overall mean, we have evidence that there is a difference (somewhere) in the population means. Figure 
<a href="#anova_concept">[anova_concept]</a>{reference-type=&quot;ref&rdquo; reference=&quot;anova_concept&rdquo;} gives a visual representation of the idea. Here, we see that most of the total variability is accounted for by the differences between the group means and the overall mean (the shaded area). Therefore, we would say that there is a difference (somewhere) among the group means.</p>
<p>The mathematical representation of Figure 
<a href="#anova_concept">[anova_concept]</a>{reference-type=&quot;ref&rdquo; reference=&quot;anova_concept&rdquo;} is in terms of &ldquo;<strong>sums of squares</strong>.&rdquo; The equation is</p>
<p>$$SSTOT=SST+SSE$$</p>
<p>where $SSTOT$ is the <strong>total sum of squares</strong> (a measure of total variability in the data), $SST$ is called the <strong>sum of squares for treatments</strong> (a measure of variability between group means and overall mean), and $SSE$ is called the <strong>sum of squares for error</strong>, a measure of variability that is left unexplained.</p>
<p>To construct the eventual test statistic, we need formulas for finding $SST$ and $SSE$. First, we need the <strong>grand mean,</strong> the overall average of the data. The formula and notation for that value is the following:</p>
<p>$$\overline{\overline{y}}=\frac{1}{N}\sum_{i=1}^{g}\sum_{j=1}^{n_{i}}y_{ij} \label{full_data_grand_mean}$$</p>
<p>where $N$ is the total number of data points in the sample. If only the individual group means $\overline{y}<em>{1},\overline{y}</em>{2},\ldots ,% \overline{y}_{g}$ are known, the grand mean can be found by taking a weighted (by the individual sample sizes) average of the group means, that is,</p>
<p>$$\overline{\overline{y}}=\frac{n_{1}\overline{y}_{1}+n_{2}\overline{y}%_{2}+\ldots +n_{g}\overline{y}_{g}}{n_{1}+n_{2}+\ldots +n_{g}} \label{grand_mean_group_means_only}$$</p>
<p>Now we can define the other formulas, starting with $SST$:</p>
<p>$$SST=\sum_{i=1}^{g}n_{i}(\overline{y_{i}}-\overline{\overline{y}})^{2} \label{SST}$$</p>
<p>If all of the group sample sizes are the same, then $n_{i}=n$ for all $i$, so the above can be simplified a bit:</p>
<p>$$SST=n\sum_{i=1}^{g}(\overline{y_{i}}-\overline{\overline{y}})^{2}\text{ [if all group sample sizes are equal].}  \label{SST_equal_n}$$</p>
<p>Next we have the formula for $SSE$:</p>
<p>$$SSE=\sum_{i=1}^{g}\sum_{j=1}^{n_{i}}(y_{ij}-\overline{y}_{i})^{2} \label{SSE}$$</p>
<p>which can be simplified if we note that for each $i$, the inner terms, $\sum_{j=1}^{n_{i}}(y_{ij}-\overline{y}_{i})^{2}$, are really just the numerators of the sample variances for each group, $s_{i}^{2}$. So we have $(n_{i}-1)s_{i}^{2}=\sum_{j=1}^{n_{i}}(y_{ij}-\overline{y}_{i})^{2}$, which means we can simplify the formula for $SSE$ to</p>
<p>$$SSE=\sum_{i=1}^{g}(n_{i}-1)s_{i}^{2}\text{ \ \ \ [simplified version of equation \ref{SSE}]}$$</p>
<p>Finally we, have $SSTOT$:</p>
<p>$$SSTOT=\sum_{i=1}^{g}\sum_{j=1}^{n_{i}}(y_{ij}-\overline{\overline{y}})^{2} \label{SSTot}$$</p>
<p>which is just the total of $SST$ and $SSE$. The more of $SSTOT$ that is made up of $SST$, the more we begin to suspect that there are differences in group means.</p>
<p>The next concept we need is <strong>degrees of freedom,</strong> which has to do with the number of independent pieces of information you are combining. Think of the ordinary sample variance formula: $s^{2}=\frac{% \sum_{i=1}^{n}(y_{i}-\overline{y})^{2}}{n-1}$. The reason we divide by $n-1$ is that if you know $n-1$ of the numbers and the sample mean, you can figure out the remaining number. For instance, if I tell you the sample mean is $% \overline{y}=6$  for a sample of $4$ numbers, and three of them are $1,8$, and $3$, then the fourth one must be $24-1-8-3=12$ (verify this for yourself). In ANOVA, degrees of freedom can be broken up by sums of squares:</p>
<p>$$\begin{aligned} \text{Total Degrees of Freedom}\text{: } &amp;&amp;DF_{TOT}=N-1 \ \text{Degrees of Freedom for Treatment}\text{: } &amp;&amp;DF_{SST}=g-1 \ \text{Degrees of Freedom for Error}\text{: } &amp;&amp;DF_{SSE}=N-g\end{aligned}$$</p>
<p>so we have</p>
<p>$$DF_{TOT}=DF_{SST}+DF_{SSE}$$</p>
<p>We will see how this all fits together when we work a few examples. First we have to define the ANOVA test. The same general four-step procedure still applies. What changes are the specifics.</p>
<p>The general four-step procedure still applies. What changes are the specifics. Let&rsquo;s see how.</p>
<ol>
<li>Specify the hypothesis:</li>
</ol>
<p>Now instead of one $\mu$ we work with several $\mu ^{\prime }s$, one for each of the $g$ groups. The ANOVA hypothesis, like the test for equal variances, is two sided by design:</p>
<p>$$\begin{aligned} H_{0} &amp;:&amp;\mu_{1}=\mu_{2}=\ldots =\mu_{g} \ H_{1} &amp;:&amp;\text{ not all }\mu_{i}\text{ are equal }\end{aligned}$$</p>
<p>Note that in the null hypothesis, you do not specify what all of the $\mu ^{\prime }s$ are equal to; you only state that they are all equal to one another. <em>Note also that the complement of</em> $H_{0}$ is not that all the means are different, but just that at least two are different* (or equivalently, not all are equal).</p>
<ol>
<li>Calculate the <strong>test statistic</strong></li>
</ol>
<p>Under the assumption that the data arise from $g$ normal distributions with possibly different means but identical standard deviations, the test statistic will be an <strong>$F$</strong> statistic,** which follows an $F$ distribution when the null hypothesis is true. Similar to the Student&rsquo;s $t$ distribution, the $F$ distribution is defined by degrees of freedom. The difference is that we have **numerator degrees of freedom,** which we call ** **$\nu_{1}$,** **and **denominator degrees of freedom**, which we call.** **The $% F_{v_{1},v_{2}}$ distribution, then is the $F$ distribution with $\nu_{1}$ numerator degrees of freedom and $\nu_{2}$ denominator degrees of freedom. The $F$ distribution takes on a variety of appearances depending on these two parameters, as you can see in Figure 
<a href="#fdist">[fdist]</a>{reference-type=&quot;ref&rdquo; reference=&quot;fdist&rdquo;}.</p>
<p>To calculate the test statistic, we compute the following:</p>
<p>$$f=\frac{SST/(g-1)}{SSE/(N-g)}=\frac{MST}{MSE}$$</p>
<p>where $MST$ stands for &ldquo;mean square for treatments&rdquo; and $MSE$ stands for &ldquo;mean square for error.&rdquo;</p>
<ol>
<li>Determine the rejection region (or compute the $p$-value)</li>
</ol>
<p>Like any test for means, unless we have software, we usually go with the rejection region approach. The the rejection region for a test with the $% \alpha$ level of significance would be computed as follows:</p>
<p>$${f_{g-1},_{N-g}:f_{g-1},_{N-g}&gt;f_{g-1,N-g,\alpha }}$$</p>
<p>If we have access to software, we can compute the $p$-value as follows: $$p-val=P(F_{g-1,N-g}&gt;f)$$</p>
<p>Notice that there is only one rejection region for this test; it is a right-tailed test. We only reject for large values of $f$.</p>
<ol>
<li>Make a conclusion</li>
</ol>
<p>If the $p$-value $\leq \alpha$, we reject $H_{0}$. If the $p$-value $% &gt;\alpha$, we fail to reject $H_{0}$. Equivalently, if $f$ lies within the rejection region, we reject $H_{0}$. If $f$ lies outside the rejection region, we fail to reject $H_{0}$.</p>
<p>In practice, the sums of squares, mean squares, $F$ statistic, $p$-value, and other information are often given in an <strong>ANOVA table</strong> similar to that in Figure 
<a href="#anovatable">[anovatable]</a>{reference-type=&quot;ref&rdquo; reference=&quot;anovatable&rdquo;}, which is the form given in Microsoft Excel. &ldquo;Between groups&rdquo; refers to the explained variability in group means and &ldquo;within groups&rdquo; refers to the unexplained variability. We will use this table extensively in the examples.</p>
<p>Let&rsquo;s work an example putting all of this together.</p>
<p>The following statistics were calculated for an experiment:</p>
<p>a). Develop the ANOVA table and fill in the information below.</p>
<p>b). State the ANOVA hypothesis</p>
<p>c). State the conclusion.</p>
<p>A study was done to determine if the amount of time people spend on the internet varies by martial status. The data, from the $2012$ General Social Survey, are summarized below.</p>
<p>a). Develop the ANOVA table and fill in the information below.</p>
<p>b). State the ANOVA hypothesis</p>
<p>c). State the conclusion in the context of the problem.</p>
<p>The ANOVA table from the example in the PowerPoint regarding the average time students in different majors spend studying per week is reproduced below.</p>
<p>a). How many groups were examined?</p>
<p>b). Is this a balanced design?</p>
<p>c). How many total observations were there?</p>
<p>d). Show how the F statistic was calculated</p>
<p>f). What important assumption seems to be violated here?</p>
<h1 id="bonferroni-method-of-multiple-comparisons">Bonferroni Method of Multiple Comparisons</h1>
<p>Recall that the ANOVA hypotheses are</p>
<p>$$H_{0}: \mu_{1}=\mu_{2}=\ldots =\mu_{g}\text{ vs. }H_{1}:\text{not all }\mu ^{\prime }s\text{ are equal}$$</p>
<p>Suppose you have rejected the ANOVA hypothesis. You can then only conclude that not all of the group means are identical. However, you don&rsquo;t know which ones differ from each other, which is a natural question to ask. As stated at the beginning of Handout 11, simply conducting several $t$ tests in the usual way will increase your chance of making at least one type I error, so we have to adjust our approach slightly.</p>
<p><strong>Multiple comparison techniques</strong> allow one to make conclusions about a collection, or <strong>family</strong>, of hypotheses while keeping the overall error rate (<strong>familywise error rate</strong>) at a given (small) level, $\alpha_{family}.$</p>
<p>Many methods exist, and I 
<a href="http://repositories.tdl.org/ttu-ir/bitstream/handle/2346/ETD-TTU-2011-08-1608/Henning_Kevin_Dissertation.pdf?sequence=2" target="_blank" rel="noopener">wrote my disseration on one</a> . We will only cover one here because it is the simplest. The basic idea of all methods is that we increase the burden of proof over a regular test or interval. We do this because each test has an $\alpha$ probability of being incorrect.</p>
<p>The <strong>Bonferroni adjustment</strong> forms confidence intervals and conducts tests at the $\frac{\alpha_{family}}{k}$ level, where $k$ is the number of tests or intervals you want to construct and control the error rate for.</p>
<p>To compare all of the groups to one another, just set $k=\binom{g}{2}=\frac{% g(g-1)}{2}.$ For example, if you have $5$ groups and you wish to compare all group means, you would set $k=\frac{5(5-1)}{2}=10.$ If $\alpha_{family}=0.05$, then you would form intervals and conduct tests at the $% \frac{0.05}{10}=0.005$ level. However, you just wanted to compare, say, $4$ pairs of means, you would set $k=4$ and you would form intervals and conduct tests at the $\frac{0.05}{4}=0.0125$ level.</p>
<p>Confidence intervals for differences between means $\mu_{i}$ and $\mu_{j}$ can be constructed by the following method</p>
<p>$$\overline{y_{i}}-\overline{y_{j}}\pm t_{\frac{_{\alpha_{family}}}{2k}% },_{N-g}\times \sqrt{MSE\left( \frac{1}{n_{i}}+\frac{1}{n_{j}}\right) }$$</p>
<p>What this interval allows us to conclude is that, with $(1-\alpha_{family})100%$ confidence **in the entire set of confidence intervals we calculate**, the difference in the two group means $\mu_{1}-\mu_{j}$ lies within the upper and lower bounds. So, if we want $95%$ confidence in the entire set of intervals, we would set $\alpha_{family}=0.05.$ The $&quot;2&quot;$ in the denominator of the above equation comes from the fact that when we form a two-sided confidence interval, we divide the $\alpha$ by 2 to obtain the correct value of $t.$</p>
<p>We can also define a hypothesis test using the Bonferroni method. What changes are the specifics. Let&rsquo;s see how.</p>
<ol>
<li>
<p>Specify the hypothesis:</p>
<p>In general, we want to test the relationship between two means,     $\mu_{i}$ and $\mu_{j}.$</p>
<p>$$\begin{aligned}     \text{(a) }H_{0} &amp;:&amp;\mu_{i}-\mu_{j}\leq d\text{ vs. }H_{1}:\mu_{i}-\mu    _{j}&gt;d\text{ } \     \text{(b) }H_{0} &amp;:&amp;\mu_{i}-\mu_{j}\geq d\text{ vs. }H_{1}:\mu_{i}-\mu    _{j}&lt;d \     \text{(c) }H_{0} &amp;:&amp;\mu_{i}-\mu_{j}=d\text{ vs. }H_{1}:\mu_{i}-\mu    _{j}\neq d\end{aligned}$$</p>
</li>
<li>
<p>Calculate the <strong>test statistic</strong></p>
<p>The test statistic will be a $t$ statistic.</p>
<p>$$t_{0}=\frac{\overline{y}_{i}-\overline{y}_{j}-d}{\sqrt{MSE(\frac{1}{n_{i}}+%     \frac{1}{n_{j}})}}$$</p>
</li>
<li>
<p>Compute the <strong>p-value</strong> or <strong>rejection region</strong></p>
<p>$$\begin{aligned}     \text{(a) }p &amp;=&amp;P(t_{N-g}&gt;t_{0}) \     \text{(b) }p &amp;=&amp;P(t_{N-g}&lt;t_{0}) \     \text{(c) }p &amp;=&amp;2\min [P(t_{N-g}&gt;t_{0}),P(t_{N-g}&lt;t_{0})]\end{aligned}$$</p>
<p>Alternatively, we can define the rejection region as follows:</p>
<p>$$\begin{aligned}     \text{(a)}{\text{ }t_{N-g} &amp;:&amp;t_{N-g}&gt;\text{ }t_{\alpha_{family}/k,N-g}}     \     \text{(b) }{t_{N-g} &amp;:&amp;t_{N-g}&lt;-t_{\alpha_{family}/k,N-g}} \     \text{(c) }{t_{N-g} &amp;:&amp;|t_{N-g}|&gt;\text{ }t_{\alpha_{family}/2k,N-g}}\end{aligned}$$</p>
</li>
<li>
<p>Make a conclusion</p>
</li>
</ol>
<p>If the $p$-value $\leq \frac{\alpha_{family}}{k}$, we reject $H_{0}.$ If the $p$-value $&gt;\frac{\alpha_{family}}{k}$, we fail to reject $H_{0}.$ Equivalently, if $t_{0}$ lies within the rejection region, we reject $H_{0}$ . If $t_{0}$ lies outside the rejection region, we fail to reject $H_{0}.$</p>
<p>In general, getting the values of $t$ requires a computer since rarely will $% \frac{\alpha_{family}}{2k}$ be a value in a table. To get the values of $t$ using Excel, you can follow Figure 
<a href="#bonf">[bonf]</a>{reference-type=&quot;ref&rdquo; reference=&quot;bonf&rdquo;} below. You would substitute in a number for &ldquo;alpha/k&rdquo; and &ldquo;N-g.&rdquo;</p>
<p><strong>Excel already knows to divide by</strong> $2$** since it assumes you want a value of** $t$** for a two-sided confidence interval. Therefore, you just simply specify** $\frac{\alpha_{family}}{k}.$</p>
<p>The following statistics were calculated for an experiment:</p>
<p>Form all $95%$ confidence intervals between the four groups so that we can be $95%$ confident in the entire set of intervals. Use the fact that $% t_{0.05/(2\ast 6),49}=2.75.$</p>
<p>There are a total of six groups to compare ($\binom{4}{2}=\frac{4(3)}{2}=6).$ From the ANOVA table, If we want to be $95%$ confident in the entire set of intervals, we use $\alpha_{family}=\frac{0.05}{6}=0.0083.$ The value of $t$ we need is $t_{0.0083/2,49}=2.75$ since there are $53$ total observations and $4$ groups, giving $N-g=53-4=49.$ MSE can be calculated as $102.47$ (check this for yourself).</p>
<p>Now we can compare the groups. The calculation for the first comparison, between Group 1 and Group 2, is shown here. The other calculations are similar; all that changes are the two means you are comparing and the two sample sizes under the square root.</p>
<p>$(30-35)\pm 2.75\sqrt{102.47\left( \frac{1}{10}+\frac{1}{14}\right) }% =[-16.5,6.5].$ Since this interval contains $0$, at the $\alpha_{family}=0.05$ level, we would fail to reject $H_{0}:\mu_{1}-\mu_{2}$; that is, we could not conclude that there was a difference in Group 1 and Group 2.</p>
<table>
<thead>
<tr>
<th><strong>Group</strong></th>
<th><strong>Interval</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>$1$ vs. $2$</td>
<td>$[-16.5,6.5]$ (no difference)</td>
</tr>
<tr>
<td>$1$ vs. $3$</td>
<td>$[-15.2,9.2]$(no difference)</td>
</tr>
<tr>
<td>$1$ vs. $4$</td>
<td>$[-21,1]$(no difference)</td>
</tr>
<tr>
<td>$2$ vs. $3$</td>
<td>$[-9.2,13.2]$(no difference)</td>
</tr>
<tr>
<td>$2$ vs. $4$</td>
<td>$[-15,5]$(no difference)</td>
</tr>
<tr>
<td>$3$ vs. $4$</td>
<td>$[-17.7,3.7]$(no difference)</td>
</tr>
</tbody>
</table>
<p>Thus, we cannot conclude at the familywise level of $0.05$ (or state with the familywise confidence level of $0.95)$ that there is a difference in any of the groups.</p>
<p>A study was done to determine if the amount of time people spend on the internet varies by martial status. The data, from the $2012$ General Social Survey, are summarized below.</p>
<p>Form all $99%$ confidence intervals for comparing Divorced to the other groups such that we can be $99%$ confident in the entire set of intervals. Use the fact that $t_{0.01/(2\ast 3),1807}=2.939.$</p>
<p>There are a total of three groups to compare (Divorced vs. Married, Divorced vs. Never Married, and Divorced vs. Separated). If we want to be $99%$ confident in the entire set of intervals, we use $\alpha_{family}=\frac{0.01% }{3}=0.0033.$ The value of $t$ we need is $t_{0.0033/2,1807}=2.939$, since there are $1811$ total observations and $4$ groups, giving $N-g=1811-4=1807.$ MSE can be calculated as $210.67$ (check this for yourself). The first interval, Divorced Vs. Married, is calculated as follows:</p>
<p>$$(8.4-9.4)\pm 2.939\sqrt{210.67\left( \frac{1}{317}+\frac{1}{900}\right) }% =[-3.8,1.8]$$</p>
<table>
<thead>
<tr>
<th><strong>Group</strong></th>
<th><strong>Interval</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Divorced vs. Married</td>
<td>$[-3.8,1.8]$(no difference)</td>
</tr>
<tr>
<td>Divorced vs. Never Married</td>
<td>$[-8.1,-2.1]$(difference)</td>
</tr>
<tr>
<td>Divorced vs. Separated</td>
<td>$[-8.2,3.2]$(no difference)</td>
</tr>
</tbody>
</table>
<p>Thus, we can conclude at the familywise level of $0.01$ (or state with the familywise confidence level of $0.99)$ that there is a difference in the average amount of time spent online per week between divorced persons and persons who have never married. Specifically, we conclude that persons who have never married spend, on average, between $2$ and $8$ more hours per week online than those who have been divorced.</p>

          </div>

          



          
          <div class="article-widget">
            
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/courses/bana3363/10-3-test-for-diff-in-variances/" rel="next">Confidence Interval for the Difference in Variances</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/courses/bana3363/12-anova-mc/" rel="prev">ANOVA - Bonferroni Method of Multiple Comparisons</a>
  </div>
  
</div>

          </div>
          
        </div>

        <div class="body-footer">
          <p>Last updated on Jul 28, 2020</p>

          






  
  

<p class="edit-page">
  <a href="https://github.com/gcushen/hugo-academic/edit/master/content/courses/BANA3363/11%20-%20ANOVA%20Basics.md">
    <i class="fas fa-pen pr-2"></i>Edit this page
  </a>
</p>




          


          


  
  



        </div>

      </article>

      <footer class="site-footer">
  

  <p class="powered-by">
    
  </p>

  
  






  <p class="powered-by">
    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
  </p>
</footer>


    </main>
  </div>
</div>


      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks",
        'slides' : "Slides"
        };
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js" integrity="sha256-pB/deHc9CGfFpJRjC43imB29Rse8tak+5eXqntO94ck=" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.37431be2d92d7fb0160054761ab79602.js"></script>

    






  
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
